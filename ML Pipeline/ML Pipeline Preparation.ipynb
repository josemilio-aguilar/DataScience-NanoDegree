{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = sqlite3.connect(\"DisasterResponse.db\")\n",
    "df = pd.read_sql_query('SELECT * FROM Message limit 1000', con = engine)\n",
    "X = df[\"message\"]\n",
    "Y = df.drop(['message', 'genre', 'id', 'original'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in clean_tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2, random_state = 45)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          2       0.00      0.00      0.00         0\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         1\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         27       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         1\n",
      "         34       0.00      0.00      0.00         0\n",
      "         36       0.00      0.00      0.00         0\n",
      "         38       0.00      0.00      0.00         1\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         45       0.00      0.00      0.00         0\n",
      "         46       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         49       0.00      0.00      0.00         0\n",
      "         52       0.00      0.00      0.00         1\n",
      "         53       0.00      0.00      0.00         0\n",
      "         55       0.00      0.00      0.00         0\n",
      "         56       0.00      0.00      0.00         0\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         0\n",
      "         62       0.00      0.00      0.00         1\n",
      "         63       0.00      0.00      0.00         1\n",
      "         64       0.00      0.00      0.00         1\n",
      "         65       0.00      0.00      0.00         1\n",
      "         66       0.00      0.00      0.00         1\n",
      "         67       0.00      0.00      0.00         1\n",
      "         69       0.00      0.00      0.00         1\n",
      "         71       0.00      0.00      0.00         0\n",
      "         73       0.00      0.00      0.00         0\n",
      "         74       0.00      0.00      0.00         0\n",
      "         75       0.00      0.00      0.00         1\n",
      "         76       0.00      0.00      0.00         1\n",
      "         77       0.00      0.00      0.00         0\n",
      "         79       0.00      0.00      0.00         0\n",
      "         81       0.00      0.00      0.00         0\n",
      "         84       0.00      0.00      0.00         0\n",
      "         85       0.00      0.00      0.00         0\n",
      "         87       0.00      0.00      0.00         0\n",
      "         92       0.00      0.00      0.00         0\n",
      "         96       0.00      0.00      0.00         1\n",
      "         99       0.00      0.00      0.00         1\n",
      "        101       0.00      0.00      0.00         1\n",
      "        102       0.00      0.00      0.00         0\n",
      "        103       0.00      0.00      0.00         0\n",
      "        107       0.00      0.00      0.00         0\n",
      "        108       0.00      0.00      0.00         0\n",
      "        110       0.00      0.00      0.00         0\n",
      "        111       0.00      0.00      0.00         1\n",
      "        112       0.00      0.00      0.00         1\n",
      "        113       0.00      0.00      0.00         0\n",
      "        114       0.00      0.00      0.00         0\n",
      "        116       0.00      0.00      0.00         0\n",
      "        120       0.00      0.00      0.00         1\n",
      "        122       0.00      0.00      0.00         0\n",
      "        123       0.00      0.00      0.00         0\n",
      "        124       0.00      0.00      0.00         1\n",
      "        125       0.00      0.00      0.00         0\n",
      "        127       0.00      0.00      0.00         1\n",
      "        128       0.00      0.00      0.00         0\n",
      "        132       0.00      0.00      0.00         0\n",
      "        133       0.00      0.00      0.00         1\n",
      "        137       0.00      0.00      0.00         1\n",
      "        140       0.00      0.00      0.00         0\n",
      "        142       0.00      0.00      0.00         0\n",
      "        143       0.00      0.00      0.00         0\n",
      "        145       0.00      0.00      0.00         1\n",
      "        146       0.00      0.00      0.00         0\n",
      "        147       0.00      0.00      0.00         0\n",
      "        152       0.00      0.00      0.00         0\n",
      "        154       0.00      0.00      0.00         1\n",
      "        159       0.00      0.00      0.00         0\n",
      "        161       0.00      0.00      0.00         0\n",
      "        162       0.00      0.00      0.00         1\n",
      "        163       0.00      0.00      0.00         0\n",
      "        167       0.00      0.00      0.00         0\n",
      "        171       0.00      0.00      0.00         1\n",
      "        172       0.00      0.00      0.00         1\n",
      "        173       0.00      0.00      0.00         1\n",
      "        174       0.00      0.00      0.00         0\n",
      "        175       0.00      0.00      0.00         1\n",
      "        176       0.00      0.00      0.00         0\n",
      "        178       0.00      0.00      0.00         0\n",
      "        182       0.00      0.00      0.00         1\n",
      "        186       0.00      0.00      0.00         1\n",
      "        192       0.00      0.00      0.00         0\n",
      "        193       0.00      0.00      0.00         1\n",
      "        197       0.00      0.00      0.00         1\n",
      "        199       0.00      0.00      0.00         1\n",
      "        201       0.00      0.00      0.00         0\n",
      "        202       0.00      0.00      0.00         0\n",
      "        204       0.00      0.00      0.00         0\n",
      "        208       0.00      0.00      0.00         0\n",
      "        210       0.00      0.00      0.00         1\n",
      "        212       0.00      0.00      0.00         1\n",
      "        214       0.00      0.00      0.00         1\n",
      "        216       0.00      0.00      0.00         1\n",
      "        220       0.00      0.00      0.00         0\n",
      "        221       0.00      0.00      0.00         0\n",
      "        222       0.00      0.00      0.00         0\n",
      "        223       0.00      0.00      0.00         1\n",
      "        226       0.00      0.00      0.00         1\n",
      "        227       0.00      0.00      0.00         1\n",
      "        230       0.00      0.00      0.00         0\n",
      "        233       0.00      0.00      0.00         1\n",
      "        236       0.00      0.00      0.00         1\n",
      "        239       0.00      0.00      0.00         1\n",
      "        244       0.00      0.00      0.00         0\n",
      "        245       0.00      0.00      0.00         1\n",
      "        246       0.00      0.00      0.00         0\n",
      "        248       0.00      0.00      0.00         1\n",
      "        255       0.00      0.00      0.00         1\n",
      "        257       0.00      0.00      0.00         0\n",
      "        258       0.00      0.00      0.00         1\n",
      "        259       0.00      0.00      0.00         1\n",
      "        262       0.00      0.00      0.00         1\n",
      "        263       0.00      0.00      0.00         0\n",
      "        268       0.00      0.00      0.00         1\n",
      "        275       0.00      0.00      0.00         0\n",
      "        282       0.00      0.00      0.00         0\n",
      "        283       0.00      0.00      0.00         1\n",
      "        284       0.00      0.00      0.00         1\n",
      "        285       0.00      0.00      0.00         0\n",
      "        288       0.00      0.00      0.00         1\n",
      "        290       0.00      0.00      0.00         0\n",
      "        291       0.00      0.00      0.00         0\n",
      "        294       0.00      0.00      0.00         0\n",
      "        296       0.00      0.00      0.00         0\n",
      "        299       0.00      0.00      0.00         1\n",
      "        318       0.00      0.00      0.00         0\n",
      "        324       0.00      0.00      0.00         0\n",
      "        333       0.00      0.00      0.00         1\n",
      "        334       0.00      0.00      0.00         1\n",
      "        339       0.00      0.00      0.00         1\n",
      "        342       0.00      0.00      0.00         0\n",
      "        344       0.00      0.00      0.00         1\n",
      "        346       0.00      0.00      0.00         0\n",
      "        349       0.00      0.00      0.00         1\n",
      "        351       0.00      0.00      0.00         1\n",
      "        353       0.00      0.00      0.00         0\n",
      "        356       0.00      0.00      0.00         1\n",
      "        357       0.00      0.00      0.00         1\n",
      "        360       0.00      0.00      0.00         0\n",
      "        363       0.00      0.00      0.00         0\n",
      "        364       0.00      0.00      0.00         1\n",
      "        365       0.00      0.00      0.00         1\n",
      "        367       0.00      0.00      0.00         1\n",
      "        372       0.00      0.00      0.00         1\n",
      "        376       0.00      0.00      0.00         1\n",
      "        379       0.00      0.00      0.00         0\n",
      "        381       0.00      0.00      0.00         0\n",
      "        383       0.00      0.00      0.00         1\n",
      "        386       0.00      0.00      0.00         0\n",
      "        387       0.00      0.00      0.00         1\n",
      "        389       0.00      0.00      0.00         1\n",
      "        398       0.00      0.00      0.00         1\n",
      "        400       0.00      0.00      0.00         0\n",
      "        406       0.00      0.00      0.00         1\n",
      "        407       0.00      0.00      0.00         0\n",
      "        416       0.00      0.00      0.00         0\n",
      "        419       0.00      0.00      0.00         1\n",
      "        420       0.00      0.00      0.00         1\n",
      "        421       0.00      0.00      0.00         1\n",
      "        425       0.00      0.00      0.00         1\n",
      "        429       0.00      0.00      0.00         1\n",
      "        433       0.00      0.00      0.00         1\n",
      "        451       0.00      0.00      0.00         0\n",
      "        454       0.00      0.00      0.00         1\n",
      "        460       0.00      0.00      0.00         1\n",
      "        463       0.00      0.00      0.00         0\n",
      "        464       0.00      0.00      0.00         0\n",
      "        468       0.00      0.00      0.00         1\n",
      "        473       0.00      0.00      0.00         1\n",
      "        474       0.00      0.00      0.00         1\n",
      "        476       0.00      0.00      0.00         1\n",
      "        482       0.00      0.00      0.00         1\n",
      "        484       0.00      0.00      0.00         1\n",
      "        485       0.00      0.00      0.00         1\n",
      "        487       0.00      0.00      0.00         1\n",
      "        488       0.00      0.00      0.00         0\n",
      "        489       0.00      0.00      0.00         1\n",
      "        499       0.00      0.00      0.00         1\n",
      "        500       0.00      0.00      0.00         1\n",
      "        502       0.00      0.00      0.00         0\n",
      "        504       0.00      0.00      0.00         1\n",
      "        509       0.00      0.00      0.00         0\n",
      "        515       0.00      0.00      0.00         1\n",
      "        516       0.00      0.00      0.00         1\n",
      "        518       0.00      0.00      0.00         1\n",
      "        521       0.00      0.00      0.00         1\n",
      "        526       0.00      0.00      0.00         1\n",
      "        528       0.00      0.00      0.00         1\n",
      "        529       0.00      0.00      0.00         0\n",
      "        531       0.00      0.00      0.00         1\n",
      "        532       0.00      0.00      0.00         1\n",
      "        536       0.00      0.00      0.00         1\n",
      "        537       0.00      0.00      0.00         0\n",
      "        538       0.00      0.00      0.00         1\n",
      "        555       0.00      0.00      0.00         0\n",
      "        558       0.00      0.00      0.00         0\n",
      "        559       0.00      0.00      0.00         1\n",
      "        561       0.00      0.00      0.00         0\n",
      "        568       0.00      0.00      0.00         0\n",
      "        572       0.00      0.00      0.00         1\n",
      "        575       0.00      0.00      0.00         1\n",
      "        577       0.00      0.00      0.00         1\n",
      "        578       0.00      0.00      0.00         1\n",
      "        585       0.00      0.00      0.00         1\n",
      "        587       0.00      0.00      0.00         1\n",
      "        589       0.00      0.00      0.00         0\n",
      "        593       0.00      0.00      0.00         1\n",
      "        595       0.00      0.00      0.00         0\n",
      "        606       0.00      0.00      0.00         1\n",
      "        607       0.00      0.00      0.00         1\n",
      "        609       0.00      0.00      0.00         0\n",
      "        613       0.00      0.00      0.00         0\n",
      "        614       0.00      0.00      0.00         1\n",
      "        615       0.00      0.00      0.00         1\n",
      "        620       0.00      0.00      0.00         0\n",
      "        622       0.00      0.00      0.00         0\n",
      "        624       0.00      0.00      0.00         1\n",
      "        625       0.00      0.00      0.00         1\n",
      "        628       0.00      0.00      0.00         0\n",
      "        636       0.00      0.00      0.00         1\n",
      "        642       0.00      0.00      0.00         0\n",
      "        643       0.00      0.00      0.00         0\n",
      "        646       0.00      0.00      0.00         1\n",
      "        648       0.00      0.00      0.00         1\n",
      "        651       0.00      0.00      0.00         1\n",
      "        655       0.00      0.00      0.00         1\n",
      "        662       0.00      0.00      0.00         1\n",
      "        663       0.00      0.00      0.00         1\n",
      "        665       0.00      0.00      0.00         1\n",
      "        666       0.00      0.00      0.00         1\n",
      "        667       0.00      0.00      0.00         1\n",
      "        668       0.00      0.00      0.00         0\n",
      "        672       0.00      0.00      0.00         1\n",
      "        675       0.00      0.00      0.00         1\n",
      "        676       0.00      0.00      0.00         1\n",
      "        678       0.00      0.00      0.00         0\n",
      "        680       0.00      0.00      0.00         1\n",
      "        682       0.00      0.00      0.00         0\n",
      "        684       0.00      0.00      0.00         0\n",
      "        685       0.00      0.00      0.00         1\n",
      "        688       0.00      0.00      0.00         1\n",
      "        695       0.00      0.00      0.00         1\n",
      "        696       0.00      0.00      0.00         1\n",
      "        702       0.00      0.00      0.00         0\n",
      "        709       0.00      0.00      0.00         0\n",
      "        713       0.00      0.00      0.00         0\n",
      "        714       0.00      0.00      0.00         1\n",
      "        717       0.00      0.00      0.00         0\n",
      "        725       0.00      0.00      0.00         1\n",
      "        727       0.00      0.00      0.00         1\n",
      "        729       0.00      0.00      0.00         1\n",
      "        730       0.00      0.00      0.00         0\n",
      "        733       0.00      0.00      0.00         1\n",
      "        744       0.00      0.00      0.00         1\n",
      "        745       0.00      0.00      0.00         1\n",
      "        746       0.00      0.00      0.00         1\n",
      "        750       0.00      0.00      0.00         0\n",
      "        752       0.00      0.00      0.00         0\n",
      "        754       0.00      0.00      0.00         1\n",
      "        755       0.00      0.00      0.00         1\n",
      "        756       0.00      0.00      0.00         1\n",
      "        758       0.00      0.00      0.00         1\n",
      "        759       0.00      0.00      0.00         1\n",
      "        763       0.00      0.00      0.00         0\n",
      "        764       0.00      0.00      0.00         0\n",
      "        766       0.00      0.00      0.00         1\n",
      "        769       0.00      0.00      0.00         1\n",
      "        773       0.00      0.00      0.00         0\n",
      "        776       0.00      0.00      0.00         1\n",
      "        777       0.00      0.00      0.00         1\n",
      "        780       0.00      0.00      0.00         0\n",
      "        782       0.00      0.00      0.00         1\n",
      "        784       0.00      0.00      0.00         1\n",
      "        797       0.00      0.00      0.00         1\n",
      "        800       0.00      0.00      0.00         1\n",
      "        801       0.00      0.00      0.00         1\n",
      "        802       0.00      0.00      0.00         0\n",
      "        809       0.00      0.00      0.00         1\n",
      "        811       0.00      0.00      0.00         1\n",
      "        816       0.00      0.00      0.00         1\n",
      "        817       0.00      0.00      0.00         1\n",
      "        821       0.00      0.00      0.00         0\n",
      "        822       0.00      0.00      0.00         0\n",
      "        830       0.00      0.00      0.00         0\n",
      "        832       0.00      0.00      0.00         0\n",
      "        833       0.00      0.00      0.00         1\n",
      "        836       0.00      0.00      0.00         1\n",
      "        837       0.00      0.00      0.00         1\n",
      "        840       0.00      0.00      0.00         0\n",
      "        846       0.00      0.00      0.00         1\n",
      "        850       0.00      0.00      0.00         1\n",
      "        852       0.00      0.00      0.00         1\n",
      "        854       0.00      0.00      0.00         1\n",
      "        855       0.00      0.00      0.00         0\n",
      "        856       0.00      0.00      0.00         0\n",
      "        857       0.00      0.00      0.00         0\n",
      "        863       0.00      0.00      0.00         1\n",
      "        864       0.00      0.00      0.00         1\n",
      "        866       0.00      0.00      0.00         1\n",
      "        867       0.00      0.00      0.00         1\n",
      "        873       0.00      0.00      0.00         1\n",
      "        883       0.00      0.00      0.00         0\n",
      "        888       0.00      0.00      0.00         1\n",
      "        890       0.00      0.00      0.00         1\n",
      "        891       0.00      0.00      0.00         1\n",
      "        896       0.00      0.00      0.00         1\n",
      "        899       0.00      0.00      0.00         0\n",
      "        900       0.00      0.00      0.00         1\n",
      "        905       0.00      0.00      0.00         1\n",
      "        906       0.00      0.00      0.00         1\n",
      "        907       0.00      0.00      0.00         0\n",
      "        910       0.00      0.00      0.00         0\n",
      "        912       0.00      0.00      0.00         1\n",
      "        917       0.00      0.00      0.00         0\n",
      "        921       0.00      0.00      0.00         1\n",
      "        925       0.00      0.00      0.00         1\n",
      "        926       0.00      0.00      0.00         1\n",
      "        929       0.00      0.00      0.00         1\n",
      "        951       0.00      0.00      0.00         1\n",
      "        956       0.00      0.00      0.00         1\n",
      "        971       0.00      0.00      0.00         0\n",
      "        983       0.00      0.00      0.00         1\n",
      "        985       0.00      0.00      0.00         1\n",
      "        986       0.00      0.00      0.00         1\n",
      "        989       0.00      0.00      0.00         1\n",
      "        990       0.00      0.00      0.00         0\n",
      "        994       0.00      0.00      0.00         1\n",
      "       1004       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.00      0.00      0.00       200\n",
      "\n",
      "related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.09      0.15        32\n",
      "          1       0.84      0.98      0.91       167\n",
      "          2       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.77      0.83      0.78       200\n",
      "\n",
      "request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.78      0.74        80\n",
      "          1       0.84      0.79      0.82       120\n",
      "\n",
      "avg / total       0.79      0.79      0.79       200\n",
      "\n",
      "offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.77      0.72        77\n",
      "          1       0.84      0.78      0.81       123\n",
      "\n",
      "avg / total       0.78      0.78      0.78       200\n",
      "\n",
      "medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95       178\n",
      "          1       0.80      0.18      0.30        22\n",
      "\n",
      "avg / total       0.90      0.91      0.88       200\n",
      "\n",
      "medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       187\n",
      "          1       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.87      0.94      0.90       200\n",
      "\n",
      "search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       191\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.91      0.95      0.93       200\n",
      "\n",
      "security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       197\n",
      "          1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.97      0.98      0.98       200\n",
      "\n",
      "military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       197\n",
      "          1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.97      0.98      0.98       200\n",
      "\n",
      "child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95       158\n",
      "          1       0.93      0.67      0.78        42\n",
      "\n",
      "avg / total       0.92      0.92      0.91       200\n",
      "\n",
      "food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       138\n",
      "          1       0.97      0.63      0.76        62\n",
      "\n",
      "avg / total       0.89      0.88      0.87       200\n",
      "\n",
      "shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       168\n",
      "          1       1.00      0.22      0.36        32\n",
      "\n",
      "avg / total       0.89      0.88      0.84       200\n",
      "\n",
      "clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       196\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.96      0.98      0.97       200\n",
      "\n",
      "money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       190\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.90      0.95      0.93       200\n",
      "\n",
      "missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       197\n",
      "          1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.97      0.98      0.98       200\n",
      "\n",
      "refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       196\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.96      0.98      0.97       200\n",
      "\n",
      "death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       193\n",
      "          1       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.93      0.96      0.95       200\n",
      "\n",
      "other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       155\n",
      "          1       0.40      0.04      0.08        45\n",
      "\n",
      "avg / total       0.69      0.77      0.69       200\n",
      "\n",
      "infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       187\n",
      "          1       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.87      0.94      0.90       200\n",
      "\n",
      "transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       193\n",
      "          1       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.93      0.96      0.95       200\n",
      "\n",
      "buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96       185\n",
      "          1       1.00      0.07      0.12        15\n",
      "\n",
      "avg / total       0.93      0.93      0.90       200\n",
      "\n",
      "electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       197\n",
      "          1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.97      0.98      0.98       200\n",
      "\n",
      "tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       199\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       193\n",
      "          1       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.93      0.96      0.95       200\n",
      "\n",
      "weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       170\n",
      "          1       1.00      0.03      0.06        30\n",
      "\n",
      "avg / total       0.88      0.85      0.79       200\n",
      "\n",
      "floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       195\n",
      "          1       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.95      0.97      0.96       200\n",
      "\n",
      "storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       193\n",
      "          1       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.93      0.96      0.95       200\n",
      "\n",
      "fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       191\n",
      "          1       1.00      0.11      0.20         9\n",
      "\n",
      "avg / total       0.96      0.96      0.94       200\n",
      "\n",
      "cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       199\n",
      "          1       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       190\n",
      "          1       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.90      0.95      0.93       200\n",
      "\n",
      "direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.74      0.72        88\n",
      "          1       0.79      0.75      0.77       112\n",
      "\n",
      "avg / total       0.75      0.74      0.75       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i, col in enumerate(y_test):\n",
    "        print(col)\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "performance(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  {'tfidf__use_idf': (True, False), \n",
    "              'clf__estimator__n_estimators': [50, 100], \n",
    "              'clf__estimator__min_samples_split': [2, 4]} \n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tfidf__use_idf': (True, False), 'clf__estimator__n_estimators': [50, 100], 'clf__estimator__min_samples_split': [2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('best', TruncatedSVD()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('disaster_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def load_data(database_filepath):\n",
    "    engine = sqlite3.connect(\"DisasterResponse.db\")\n",
    "    df = pd.read_sql_query('SELECT * FROM Message limit 1000', con = engine)\n",
    "    X = df[\"message\"]\n",
    "    Y = df.drop(['message', 'genre', 'id', 'original'], axis = 1)\n",
    "return X,Y\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in clean_tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2, random_state = 45)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    def performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i, col in enumerate(y_test):\n",
    "        print(col)\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "performance(pipeline, X_test, y_test)\n",
    "\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    with open('disaster_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) == 3:\n",
    "        database_filepath, model_filepath = sys.argv[1:]\n",
    "        print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "        X, Y, category_names = load_data(database_filepath)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "        \n",
    "        print('Building model...')\n",
    "        model = build_model()\n",
    "        \n",
    "        print('Training model...')\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        print('Evaluating model...')\n",
    "        evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "        print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "        save_model(model, model_filepath)\n",
    "\n",
    "        print('Trained model saved!')\n",
    "\n",
    "    else:\n",
    "        print('Please provide the filepath of the disaster messages database '\\\n",
    "              'as the first argument and the filepath of the pickle file to '\\\n",
    "              'save the model to as the second argument. \\n\\nExample: python '\\\n",
    "              'train_classifier.py ../data/DisasterResponse.db classifier.pkl')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
